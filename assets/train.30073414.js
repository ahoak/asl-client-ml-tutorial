import{t as r,V as p,f as T,e as f,a as h,J as L,A as x,g as v,h as S,i as b,k as s,T as m,m as F,n as $}from"./utils.05904ff8.js";const B="ASL Fingerspelling Model Tutorial",A="Train ASL Fingerspelling ML Model using Tensorflowjs",j="ASL Fingerspelling Tutorial \u{1F44B}",D="",O="",V={github:"https://github.com/ahoak/asl-client-ml-tutorial",twitter:"https://twitter.com/amber_hoak"},X=!1,Y=[{step:1,description:"Load Data",helperText:"Load preprocessed data by pressing the button",name:"loadData",readOnly:"true"},{step:2,description:"Create Model",helperText:"creating a feed-forward model. We will use 5 layers with relu activation function. Function must return the model.",name:"createModel",readOnly:"false"},{step:3,description:"Configure Model",helperText:"edit function configureModel() by using the Tf.compile API. We will use an adam optimizer, and add correct loss function.",name:"configureModel",readOnly:"false"},{step:4,description:"Train Model",helperText:"edit function trainModel() by using the Tf.fit API. Set the following parameters: epochs, batchSize,validationData, callbacks. Hint, you may need to transform your data into tensors ",name:"trainModel",readOnly:"false"},{step:5,description:"Cleanup",helperText:"Remove tensors used for model training ",name:"cleanupTensors",readOnly:"true"},{step:6,description:"Download Model Files",helperText:"Click the button to download your shiney new model. We will use this in our webapp.",name:"exportModel",readOnly:"true"}],_=[{step:1,description:"Import Model",helperText:"Import a pre-trained model to perform inference with."},{step:2,description:"Extract and Process Joint Positions",helperText:"Extract the hand joint positions from within an image."},{step:3,description:"Classify",helperText:"Run inference with the normalized joint positions to get a classification (ASL sign)."},{step:4,description:"Cleanup",helperText:"Cleanup the tensors used while infering."},{step:5,description:"Run",helperText:"Run prediction on the model"}],k={metaTitle:B,metaDescription:A,name:j,theme:D,avatarImage:O,social:V,showDataVideo:X,trainTutorialSteps:Y,predictSteps:_},N=`
// READ-ONLY
function cleanupTensors(
  data: [Tensor, Tensor, Tensor, Tensor]
): void {
  const [xTensor, yTensor, xValidateTensor, yValidateTensor] = data

  // Free up memory resources by cleaning up intermediate tensors (i.e the tensors above)
  xTensor.dispose();
  yTensor.dispose();
  xValidateTensor.dispose();
  yValidateTensor.dispose();
    

}`,P=`
 function cleanupTensorsSolution(
  data: [Tensor, Tensor, Tensor, Tensor],

): void {
  const [xTensor, yTensor, xValidateTensor, yValidateTensor] = data

  xTensor.dispose();
  yTensor.dispose();
  xValidateTensor.dispose();
  yValidateTensor.dispose();

}`;function R(o,e){return new Function("data","tf","tfjs",`return (${o.replace(/export/g,"")})`)(e,r,r)}async function H(o,e){try{await o(e)}catch(t){const n=`${t}`;return{valid:!1,errors:[{type:p.Unknown,detail:n}]}}return{valid:!0,errors:[],data:[]}}const U=Object.freeze(Object.defineProperty({__proto__:null,template:N,solution:P,implementation:R,validate:H},Symbol.toStringTag,{value:"Module"})),q=`
// https://js.tensorflow.org/api/latest/#tf.LayersModel.compile
/**
 * @param {tf.LayersModel} model The model to run the compile with

 */
function configureModel(model: LayersModel):LayersModel {
  // Configures and prepares the model for training and evaluation. Compiling outfits the model with an optimizer, loss, and/or metrics
  
  // Optimizer: The job of the optimizer is to decide how much to change each parameter in the model, given the current model prediction.
  // Loss Function: Its goal is to give a single number for "how wrong" the model's prediction was. The loss is computed on every batch of data so that the model can update its weights.
  // List of Metrics: Similar to losses, metrics compute a single number, summarizing how well our model is doing. The metrics are usually computed on the whole data at the end of each epoch
 
  model.compile({
    // Adam changes the learning rate over time which is useful.
    // https://js.tensorflow.org/api/latest/#Training-Optimizers
    optimizer:  /*<input>*/, //optimizer options: tf.train.sgd, tf.train.momentum, tf.train.adagrad, tf.train.ada, tf.train.adam, tf.train.adamax, tf.train.rmsprop

    // Use the correct loss function. https://js.tensorflow.org/api/latest/#Training-Losses
    // If 2 classes of data, use binaryCrossentropy else use categoricalCrossentropy is used if more than 2 classes and output of our model is a probability distribution.
    // This measures the error between the probability distribution generated by the last layer of our model and the probability distribution given by our true label
    loss:  /*<input>*/,
    // As this is a classification problem you can record accuracy in the logs too!
    metrics: ['accuracy'],
  });
    return model
  }
  `,W=`
  // https://js.tensorflow.org/api/latest/#tf.LayersModel.compile
  /**
   * @param {tf.LayersModel} model The model to run the compile with
  
   */
  function configureModelSolution(model: LayersModel):LayersModel {
      model.compile({
        optimizer: tf.train.adam(0.001),
        loss: 'categoricalCrossentropy',
        metrics: ['accuracy'],
      });
      return model
  }
    `;function J(o,e){return new Function("model","tf","tfjs",`return (${o.replace(/export/g,"")})`)(e,r,r)}async function Z(o,e){let t=e;try{if(t=await o(e),!e.evaluate(T([1,63]),T([1,26])))return f(`
      The model does not seemed to be compiled or compiled correctly'
      `)}catch(n){const i=`${n}`;return{valid:!1,errors:[{type:p.Unknown,detail:i}]}}return{valid:!0,errors:[],data:[t]}}const Q=Object.freeze(Object.defineProperty({__proto__:null,template:q,solution:W,implementation:J,validate:Z},Symbol.toStringTag,{value:"Module"})),G=`
// Create a feed-forward model using the tf.sequential (https://js.tensorflow.org/api/latest/#sequential)
function createModel(classes: string[]):LayersModel {
 
  const model = tf.sequential({
    layers: [
      // Fill in the inputShape (hint this is equal to mediapipe hands output per image = 63)
      // Fill in units (nuerons) in range 50-75
      // Want to play with other activation functions, go for it! 
      // This interactive app visualizes tfjs options:https://polarisation.github.io/tfjs-activation-functions/
      tf.layers.dense({ inputShape: [/*<input>*/], units: /*<input>*/, activation: 'relu' }),

      // Fill in units (nuerons) in range 100-300??
      tf.layers.dense({ units: /*<input>*/, activation: 'relu' }),

      // Add a final dense layer wtih number of nuerons equal to classes (i.e classes.length )
      tf.layers.dense({ units: /*<input>*/, activation: 'softmax' }),
    ],
  });

  // Uncomment below statement to check the output. 
  // console.log(model.summary())
  return model;
}
`,K=`
// Create a feed-forward model using the tf.sequential (https://js.tensorflow.org/api/latest/#sequential)
function createModelSolution(classes: string[]):LayersModel {
  // Create a feed-forward model
  const model = tf.sequential({
    layers: [
      tf.layers.dense({ inputShape: [63], units: 63, activation: 'relu' }),
      tf.layers.dense({ units: 256, activation: 'relu' }),
      tf.layers.dense({ units: classes.length, activation: 'softmax' }),
    ],
  });
  return model;
}`;function ee(o){return new Function("classes","tf","tfjs",`return (${o.replace(/export/g,"")})`)(h,r,r)}async function te(o){let e;try{if(e=await o(h),!e)return f(`"We couldn't find your model. Did you implement createModel function? If so, check that you return your model`)}catch(t){const n=`${t}`;return{valid:!1,errors:[{type:p.Unknown,detail:n}]}}return{valid:!0,errors:[],data:[e]}}const ne=Object.freeze(Object.defineProperty({__proto__:null,template:G,solution:K,implementation:ee,validate:te},Symbol.toStringTag,{value:"Module"}));function oe(o,e){const t=document.createElement("a");t.setAttribute("href","data:application/zip;base64,"+e),t.setAttribute("download",o),t.style.display="none",document.body.appendChild(t),t.click(),document.body.removeChild(t)}const ie=`
// READ-ONLY
async function exportModel(model: LayersModel, ArrayBufferModelSaverInstance,  download: (filename: string, data: string)=> void): Promise<void> {
    // checkout https://www.tensorflow.org/js/guide/save_load for info on the async method 'save'
    // We can save the topology and weights of a model
    // Topology: This is a file describing the architecture of a model (i.e. what operations it uses). It contains references to the models's weights which are stored externally.
    // Weights: These are binary files that store the weights of a given model in an efficient format. They are generally stored in the same folder as the topology.

    const zip = new JSZip();
    const files = await model.save(ArrayBufferModelSaverInstance);
    const f = files as unknown as { data: { [key: string]: ArrayBuffer } };
  
    Object.keys(f.data).forEach((fileName, index) => {
      if (index === 0) {
        zip.file(fileName, JSON.stringify(f.data[fileName]));
      } else {
        zip.file(fileName, f.data[fileName]);
      }
    });

    // download to zip file for upload in part 2 of the tutorial

    await zip.generateAsync({ type: 'base64' }).then(
      function (base64) {
        download('model.zip', base64);
      },
      function (error) {
        console.warn(error);
      },
    );
   
    // optional: save to localstorage or downloads
    // await model.save('localstorage://model');
    // await model.save('downloads://model')
}
`,se=`
async function exportModelSolution(model: LayersModel, ArrayBufferModelSaverInstance,  download: (filename: string, data: string)=> void): Promise<void> {
  // checkout https://www.tensorflow.org/js/guide/save_load for info on the async method 'save'
  // We can save the topology and weights of a model
  // Topology: This is a file describing the architecture of a model (i.e. what operations it uses). It contains references to the models's weights which are stored externally.
  // Weights: These are binary files that store the weights of a given model in an efficient format. They are generally stored in the same folder as the topology.

  const zip = new JSZip();
  const files = await model.save(ArrayBufferModelSaverInstance);
  const f = files as unknown as { data: { [key: string]: ArrayBuffer } };

  Object.keys(f.data).forEach((fileName, index) => {
    if (index === 0) {
      zip.file(fileName, JSON.stringify(f.data[fileName]));
    } else {
      zip.file(fileName, f.data[fileName]);
    }
  });

  // download to zip file for upload in part 2 of the tutorial

  // await zip.generateAsync({ type: 'base64' }).then(
  //   function (base64) {
  //     download('model.zip', base64);
  //   },
  //   function (error) {
  //     console.warn(error);
  //   },
  // );
 
  // optional: save to localstorage or downloads
  // await model.save('localstorage://model');
  // await model.save('downloads://model')
}
`;function ae(o,e,t,n){return new Function("model","ArrayBufferModelSaver","download","tf","tfjs","JSZip",`return (${o.replace(/export/g,"")})`)(e,t,n,r,r,L,x)}async function re(o,e){try{await o(e,new x,oe)}catch(t){const n=`${t}`;return{valid:!1,errors:[{type:p.Unknown,detail:n}]}}return{valid:!0,errors:[]}}const le=Object.freeze(Object.defineProperty({__proto__:null,template:ie,solution:se,implementation:ae,validate:re},Symbol.toStringTag,{value:"Module"})),de=`
// READ-ONLY
// Loads tensors based on image data processed using mediapipe hands model
// loads zip folder located in assets. Encodes Y-values (letter names) using one-hot encoding
// shuffles and splits data into training, validation, test sets

async function loadTensorData(
  loadTensors: (folder: jsZipInstance) => Promise<{ [key: string]: number[][] }>,
  assetURL: string,
  classes: string[]
): Promise<[Tensor, Tensor, Tensor, Tensor, Tensor, Tensor]> {
  // Fetch pre-processed data, data is extracted using mediapipe hands model
  // https://google.github.io/mediapipe/solutions/hands.html from this dataset: 
  // https://www.kaggle.com/datasets/grassknoted/asl-alphabet
  const zippedModelBuffer = await (await fetch(assetURL)).arrayBuffer();
  const zipFolder = await jszip.loadAsync(zippedModelBuffer);
  const data = await loadTensors(zipFolder);
  // Check inspector to view data
  console.log("data", data)
/*
  Encodes data useing one hot encoding and splits data into training and test set
  returns array of Tensors;
*/
  function encodeAndSplitData(
    data: {[key: string]: number[][];},
    classes: string[],
    trainSplit = 0.8,
    valSplit = 0.1,
    testSplit = 0.1,
  ): [Tensor, Tensor, Tensor, Tensor, Tensor, Tensor] {
    const X: number[][] = [];
    const Y: number[] = [];
  
    Object.keys(data).forEach((cls, index) => {
      const clsData = data[cls];
      clsData.forEach((item) => {
        X.push(item);
        Y.push(index);
      });
    });
    tf.util.shuffleCombo(X, Y);
    // tensor shape [60581, 63]
    const xTensor = tf.tensor(X);
    console.log('xTensor', xTensor);
    // tensor shape [60581, 26]

    // Use one-hot encoding to encode label data
    const oneHotOutputs = tf.oneHot(tf.tensor1d(Y, 'int32'), classes.length);
  
    const trainSize = Math.floor(trainSplit * X.length);
    const valSize = Math.floor(valSplit * X.length);
    const testSize = Math.floor(testSplit * X.length);
    const trainY = oneHotOutputs.slice([0], trainSize);
    const validationY = oneHotOutputs.slice([trainSize], valSize);
    const testY = oneHotOutputs.slice([X.length - testSize], testSize);
  
    const trainX = xTensor.slice([0], trainSize);
    const validationX = xTensor.slice([trainSize], valSize);
    const testX = xTensor.slice([X.length - testSize], testSize);
  
    return [trainX, trainY, validationX, validationY, testX, testY];
  }

  // call above function to get training data split 
  const [trainX, trainY, validationX, validationY, testX, testY] =  encodeAndSplitData(data, classes)

  
  return [trainX, trainY, validationX, validationY, testX, testY];
}


`,ce=`
// Loads tensors based on image data processed using mediapipe hands model
// loads zip folder located in assets
async function loadTensorDataSolution(
  loadTensors: (folder: jsZipInstance) => Promise<{ [key: string]: number[][] }>,
  assetURL: string,
  classes: string[]
): Promise<[Tensor, Tensor, Tensor, Tensor, Tensor, Tensor]> {
  // Fetch pre-processed data, data is extracted using mediapipe hands model
  // https://google.github.io/mediapipe/solutions/hands.html from this dataset: 
  // https://www.kaggle.com/datasets/grassknoted/asl-alphabet
  const zippedModelBuffer = await (await fetch(assetURL)).arrayBuffer();
  const zipFolder = await jszip.loadAsync(zippedModelBuffer);
  const data = await loadTensors(zipFolder);
/*
  Encodes data useing one hot encoding and splits data into training and test set
  returns array of Tensors;
*/
  function encodeAndSplitData(
    data: {[key: string]: number[][];},
    classes: string[],
    trainSplit = 0.8,
    valSplit = 0.1,
    testSplit = 0.1,
  ): [Tensor, Tensor, Tensor, Tensor, Tensor, Tensor] {
    const X: number[][] = [];
    const Y: number[] = [];
  
    Object.keys(data).forEach((cls, index) => {
      const clsData = data[cls];
      clsData.forEach((item) => {
        X.push(item);
        Y.push(index);
      });
    });
    tf.util.shuffleCombo(X, Y);
    // tensor shape [60581, 63]
    const xTensor = tf.tensor(X);
    // tensor shape [60581, 26]
    const oneHotOutputs = tf.oneHot(tf.tensor1d(Y, 'int32'), classes.length);
  
    const trainSize = Math.floor(trainSplit * X.length);
    const valSize = Math.floor(valSplit * X.length);
    const testSize = Math.floor(testSplit * X.length);
    const trainY = oneHotOutputs.slice([0], trainSize);
    const validationY = oneHotOutputs.slice([trainSize], valSize);
    const testY = oneHotOutputs.slice([X.length - testSize], testSize);
  
    const trainX = xTensor.slice([0], trainSize);
    const validationX = xTensor.slice([trainSize], valSize);
    const testX = xTensor.slice([X.length - testSize], testSize);
  
    return [trainX, trainY, validationX, validationY, testX, testY];
  }

  // call above function to get training data split 
  const [trainX, trainY, validationX, validationY, testX, testY] =  encodeAndSplitData(data, classes)

  
  return [trainX, trainY, validationX, validationY, testX, testY];
}

`;function ue(o){return new Function("loadAsync","jszip","jsZipInstance","tf","tfjs","assetURL","classes",`return (${o.replace(/export/g,"")})`)(v,S,S,r,r,b,h)}async function he(o){let e;try{if(e=await o(v,b,h),!e||e.length<4)return f(`
          data did not load
      `)}catch(t){const n=`${t}`;return{valid:!1,errors:[{type:p.Unknown,detail:n}]}}return{valid:!0,errors:[],data:[e]}}const pe=Object.freeze(Object.defineProperty({__proto__:null,template:de,solution:ce,implementation:ue,validate:he},Symbol.toStringTag,{value:"Module"})),fe=`

async function trainModel(
  model: LayersModel,
  xTensor: Tensor, 
  yTensor: Tensor, 
  xValidateTensor: Tensor, 
  yValidateTensor: Tensor, 
  callbacks: {
    onBatchEnd: (batch: number, logs?: Logs) => void;
    onEpochEnd: (epoch: number) => void;
  },
  numEpochs = 2
): Promise<History> {


  // Since our data fits in memory, we can use the model.fit() api. 
  // https://js.tensorflow.org/api/latest/#tf.LayersModel.fit

  return await model.fit( /*<InputValue>*/, /*<OutputValue>*/, {
    epochs: numEpochs,
    batchSize: 128,
    verbose: 1,
    validationData: [/*<InputValidationValue>*/, /*<OutputValidationValue> */],
    callbacks: callbacks
   });

   /* 
   Under the hood, model.fit() can do a lot for us:

    Splits the data into a train and validation set, and uses the validation set to measure progress during training.
    Shuffles the data but only after the split. To be safe, you should pre-shuffle the data before passing it to fit().
    Splits the large data tensor into smaller tensors of size batchSize.
    Calls optimizer.minimize() while computing the loss of the model with respect to the batch of data.
    It can notify you on the start and end of each epoch or batch. In our case, we are notified at the end of every batch using the callbacks.onBatchEndoption. Other options include: onTrainBegin, onTrainEnd, onEpochBegin, onEpochEnd and onBatchBegin.
    It yields to the main thread to ensure that tasks queued in the JS event loop can be handled in a timely manner.
    Read more: https://www.tensorflow.org/js/guide/train_models
   */
}
`,me=`
 async function trainModelSolution(
  model: LayersModel,
  xTensor: Tensor, 
  yTensor: Tensor, 
  xValidateTensor: Tensor, 
  yValidateTensor: Tensor, 
  callbacks: {
    onBatchEnd: (batch: number, logs?: Logs) => void;
    onEpochEnd: (epoch: number) => void;
  },
  numEpochs = 2,
): Promise<History> {

  return await model.fit(xTensor, yTensor, {
    epochs: numEpochs,
    batchSize: 128,
    verbose: 1,
    validationData: [xValidateTensor, yValidateTensor],
    callbacks: callbacks
  });

}`;function ge(o,e,t,n,i,a,l,u){return new Function("model","xTensor","yTensor","xValidateTensor","yValidateTensor","callbacks","numEpochs","tf","tfjs",`return (${o.replace(/export/g,"")})`)(e,t,n,i,a,l,u,r,r)}async function ye(o,e,t,n,i,a,l,u){try{const d=await o(e,t,n,i,a,l,u);if(d){if(!d.params)return f(`
      Looks like you didn't put any parameters in your fit function'
      `)}else return f(`
      Looks like you didn't return anything. Please return value from model.fit()'
      `)}catch(d){const c=`${d}`;return{valid:!1,errors:[{type:p.Unknown,detail:c}]}}return{valid:!0,errors:[],data:[]}}const ve=Object.freeze(Object.defineProperty({__proto__:null,template:fe,solution:me,implementation:ge,validate:ye},Symbol.toStringTag,{value:"Module"})),y={configureModel:Q,createModel:ne,cleanupTensors:U,exportModel:le,trainModel:ve,loadData:pe};let be=()=>({events:{},emit(o,...e){let t=this.events[o]||[];for(let n=0,i=t.length;n<i;n++)t[n](...e)},on(o,e){return this.events[o]?.push(e)||(this.events[o]=[e]),()=>{this.events[o]=this.events[o]?.filter(t=>e!==t)}}});const g="validated",we="validationInProgress",Te="validationComplete";class Se{#s=0;#n;#o;#t;#l=!1;#e=[];#a;#d;#r;#p;constructor(e){this.#s=e.stepCount??0,this.#n=e.stepRecord,this.#o=e.element,this.#t=e.name,this.#d=localStorage.getItem(`build-ts:${this.#t}`),this.#r=e.solutionElement,this.#a=be(),this.setEventListener()}set show(e){e?this.#o.setAttribute("style","display: flex;width: 100%;height:calc(100vw / 2)"):this.#o.setAttribute("style","display:none;")}showSolution(e){this.#r&&(e?this.#r.setAttribute("style","display: flex;width: 100%;height:calc(100vw / 2)"):this.#r.setAttribute("style","display:none;"))}set code(e){this.#o.setAttribute("code",e)}set readonly(e){this.#o.toggleAttribute("readonly",e)}get solutionElement(){return this.#r}resetCodeToDefault(){this.code=this.#n.template,localStorage.removeItem(`build:${this.#t}`),localStorage.removeItem(`build-ts:${this.#t}`),this.#d=null,this.#l=!1}on(e,t){return this.#a.on(e,t)}set overrideEventListener(e){this.#p=e}setEventListener(){this.#o.addEventListener("change",async e=>{const t=e,n=!t.detail.hasSyntaxErrors,i=t.detail.transpiledCode;n&&(localStorage.setItem(`build-ts:${this.#t}`,t.detail.transpiledCode),localStorage.setItem(`build:${this.#t}`,t.detail.code),this.#d=t.detail.transpiledCode,this.#p||await this.handleEvalInput(i))})}set funcInput(e){this.#e=e}setCodeFromCacheOrDefault(){this.code=localStorage.getItem(`build:${this.#t}`)??this.#n.template}async runCachedCode(){try{this.#d&&await this.handleEvalInput(this.#d)}catch(e){console.warn(e)}}async handleEvalInput(e){this.#a.emit(we,this.#t,this.#s);const t=e??this.#o.getAttribute("code")??"",n=this.#n.implementation(t,...this.#e);if(this.#n.validate)try{const i=await this.#n.validate(n,...this.#e);this.#o.setAttribute("validation-issues",JSON.stringify(i.valid?[]:i.errors)),this.#l=i.valid,this.#l&&this.#a.emit(g,i)}catch(i){console.log(i)}this.#a.emit(Te,this.#t,this.#s,this.#l)}get isValid(){return this.#l}}const C=".loading-element",z=".train-button",Me=".output-container",w="#validation-status";function Ee(){const o=s(Me);o.style.visibility="visible";const e=s(w);e.innerHTML="Validating solution...";const t=s(C);t.style.visibility="visible"}function M(o,e,t){const n=s(w);n.innerHTML=t;const i=s(C);if(i.style.visibility="hidden",e){const a=s(`#tutorial-step${o}`),l=k.trainTutorialSteps.find(d=>d.step===o);l&&a&&(a.innerHTML=`\u2705${l.description}`);const u=s(z);u.disabled=!1}}function xe(){const o=s(w);o.innerHTML="";const e=s(z);e.disabled=!0}const ke=new Map([["loadData","\u2714\uFE0F Data loaded \u{1F4BE}"],["encodeAndSplitData"," \u2714\uFE0F Great job! Training data is ready"],["createModel","\u2714\uFE0F Yay! Model created! \u{1F389}"],["configureModel","\u2714\uFE0F Look at you go! Model is configured."],["trainModel","\u2714\uFE0F Training complete!\u{1F45F}"],["cleanupTensors","\u2714\uFE0F Goodbye tensors!\u{1F44B}"],["exportModel","\u2714\uFE0F Downloaded"]]);function Ce(o,e){let t="";return o==="setTensorFlowBackend"&&e?t=`\u2714\uFE0F Nice work! You are using ${e}.`:t=ke.get(o)??"",t}const ze=k,E=2;class Ie{#s=E;#n=1;#o=405*2;#t=0;#l=!1;#e;#a=!1;#d=s("#output-element");#r=s(".training-feedback-container");#p=s(".training-progress-bar");#w=document.querySelectorAll("code-step");#S=s(".training-progress-bar");#f=s(".train-button");#g=s(".view-solution-button");#y=s(".reset-button");#m=s(".training-stop-button");#h=s(".training-start-button");#T=s(".download-button");#v=!0;#b=!1;#c=[m,m,m,m];#i;#u={};#M={};constructor(e){this.#s=e?.epochs??E}init(){this.#f.disabled=!0,this.#f.onclick=this.handleNextButtonClick,this.#g.onclick=this.handleSolutionButtonClick,this.#y.onclick=this.handleResetButtonClick,this.#m.onclick=this.handleStopTrainingClick,this.#h.onclick=this.handlestartTrainingClick,this.#T.onclick=this.handleDownloadClick,this.mapCodeSteps()}mapCodeSteps(){const e=Object.keys(y).reduce((t,n)=>(t[n]={valid:!1,...y[n]},t),{});this.initCodeSteps(e)}initCodeSteps(e){const t={};this.#w.forEach(n=>{const i=n.getAttribute("name")??"";if(/-solution/.test(i)){const l=i.replace("-solution","");t[l]=n}}),this.#w.forEach(n=>{const i=n.getAttribute("name")??"",a=n.getAttribute("step")??"",l=y[i];if(i&&l){const u=e[i];let d;t[i]&&(d=t[i],d.setAttribute("code",u.solution),d.toggleAttribute("readonly",!0));const c=new Se({stepRecord:u,element:n,name:i,stepCount:+a,solutionElement:d});switch(this.#u[i]=c,this.#M[a]=i,i){case"loadData":c.funcInput=[v,b,h],c.on(g,this.handleDataSplitValidation);break;case"createModel":c.funcInput=[r,h],c.on(g,this.handleModelCreation);break;case"configureModel":c.on(g,this.handleConfigureModel);break}i!=="exportModel"&&(c.on("validationInProgress",this.handleValidationStarted),c.on("validationComplete",this.handleValidationComplete))}else console.error("Expected code-step to have a step attribute!")})}handleValidationStarted=(e,t)=>{this.#e?.step===t&&(Ee(),e==="trainModel"&&(this.#m.style.display="inline-flex"))};handleValidationComplete=(e,t,n)=>{if(this.#e?.step===t){let i="validation failed";if(n){let a;t===2&&(a=F()),i=Ce(e,a)}e==="trainModel"&&this.#b,M(t,n,i)}};handleResetButtonClick=()=>{const e=this.#e?.name??"";this.#u[e].resetCodeToDefault()};handleStopTrainingClick=()=>{this.#v=!1,this.#h.disabled=!1};onBatchEnd=(e,t)=>{this.#l||(this.#l=!0,this.#r.style.display="inline-block"),!this.#v&&this.#i&&(this.#i.stopTraining=!0);const n=this.#n*this.#o+(e+1),i=this.#s*this.#o,a=n/i*100;this.#S.value=a,this.#r.innerHTML=`
      Epoch: ${this.#n} Batch: ${e}
      <br>
      Loss: ${t?.loss.toFixed(3)??""}
      <br>
      Accuracy: ${t?.acc.toFixed(3)??""}
      <br>
      `};onEpochEnd=e=>{const t=Date.now()-this.#t;this.#n=e+1;const n=this.#s-e,i=t*n,[a,l]=$(i);this.#p.innerHTML=`${a} ${l?"minutes":"seconds"} remaining`,this.#t=Date.now(),e===this.#s-1&&(this.#b=!0)};handleConfigureModel=e=>{e.valid&&e.data&&e.data.length>0&&(this.#i=e.data[0])};handleModelCreation=e=>{e.valid&&e.data&&e.data.length>0?this.#i=e.data[0]:console.log("no data provided to ModelBuilder, please retry load data function")};handleDataSplitValidation=e=>{e.valid&&e.data&&e.data.length>0?this.#c=e.data[0]:console.log("no data provided to ModelBuilder, please retry load data function")};handleNextButtonClick=()=>{const e=this.#e?.step??1;this.onStepChange(e+1)};onStepChange(e){if(this.#e){const t=this.#e.name;this.#a&&this.toggleSolution(!1,t);const n=this.#u[t];n.show=!1}xe(),e!==void 0&&this.setCurrentStep(e)}handleSolutionButtonClick=()=>{const e=!this.#a,t=this.#e?.name??"";this.toggleSolution(e,t)};toggleSolution(e,t){this.#a=e,this.#u[t].showSolution(e)}handlestartTrainingClick=async()=>{const e=this.#u.trainModel;this.#i&&e&&(this.#i.stopTraining=!1,this.#v=!0,this.#n=0,this.#h.disabled=!0,this.#b=!1,this.#f.disabled=!0,await e.runCachedCode())};handleDownloadClick=async()=>{const e=this.#u.exportModel;this.#i&&e&&await e.runCachedCode()};handleStepChange(e,t="false"){const n=this.#u[e];n?(n.setCodeFromCacheOrDefault(),t&&(n.readonly=t==="true"),e==="cleanupTensors"&&(n.funcInput=[this.#c]),(e==="configureModel"||e==="exportModel")&&this.#i&&(n.funcInput=[this.#i,r]),e==="trainModel"&&this.#i?(console.log("this.#dataTensors",this.#c),n.funcInput=[this.#i,this.#c[0],this.#c[1],this.#c[2],this.#c[3],{onBatchEnd:this.onBatchEnd,onEpochEnd:this.onEpochEnd},this.#s],n.overrideEventListener=!0,this.#h.style.display="inline-flex",this.#m.style.display="inline-flex"):(this.#m.style.display="none",this.#h.style.display="none",this.#r.style.display="none"),e==="exportModel"&&(n.overrideEventListener=!0,this.#T.style.display="inline-flex",this.#f.style.display="none"),t==="true"?(this.#g.disabled=!0,this.#y.disabled=!0):(this.#g.disabled=!1,this.#y.disabled=!1),n.show=!0):console.error(`Instance of StepViewer for ${e} is not found`)}setCurrentStep(e){const t=ze.trainTutorialSteps.find(n=>n.step===e);t!=null&&(this.#e=t,Le(this.#e.step),Fe(this.#e.step-1),this.#d.innerHTML=`${this.#e.step}. ${this.#e.description} `,this.handleStepChange(this.#e.name,this.#e.readOnly))}}function Le(o){const e=document.querySelector(`#tutorial-step${o}`);e&&(e.style.fontWeight="bold")}function Fe(o){const e=document.querySelector(`#tutorial-step${o}`);e&&(e.style.fontWeight="revert")}const I=new Ie;I.init();I.setCurrentStep(1);
